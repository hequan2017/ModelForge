# 损失函数（Loss Function）

## 简单理解

**损失函数**就是"评分系统"，用一个数字来衡量模型预测得有多"差"。Loss 越小，模型越好。

---

## 类比解释

想象你在玩飞镖：

```
        ◎ 靶心（正确答案）
       ╱│╲
      ╱ │ ╲
     ╱  │  ╲
    ╱   │   ╲
   ●────┼────→  你的飞镖（模型预测）
        │
        └── Loss = 距离靶心有多远
```

- **靶心** = 正确答案（标签）
- **飞镖位置** = 模型的预测结果
- **Loss** = 飞镖离靶心的距离
- **训练目标** = 让 Loss 越来越小

---

## 常见损失函数

### 1. 交叉熵损失（Cross Entropy Loss）

**用途**：分类任务、语言模型

```
预测下一个词是什么：

正确答案：[0, 0, 1, 0, 0]  ← "猫" 的位置是 1
模型预测：[0.1, 0.1, 0.6, 0.1, 0.1]  ← 模型认为 60% 是 "猫"

Loss = -log(0.6) = 0.51  ← 预测对了，Loss 较小

如果模型预测错了：
模型预测：[0.1, 0.6, 0.1, 0.1, 0.1]  ← 模型认为 60% 是 "狗"

Loss = -log(0.1) = 2.30  ← 预测错了，Loss 很大
```

### 2. 均方误差（MSE Loss）

**用途**：回归任务

```
预测房价：

正确答案：100 万
模型预测：90 万

Loss = (100 - 90)² = 100
```

### 3. 语言模型损失

**用途**：大模型训练

```
输入："今天天气"
正确答案："很好"
模型预测：
  - "很" 的概率：0.8  → Loss = -log(0.8) = 0.22
  - "好" 的概率：0.7  → Loss = -log(0.7) = 0.36

总 Loss = 0.22 + 0.36 = 0.58
```

---

## 训练过程中的 Loss

```
Epoch 1: Loss = 2.5  ████████████████████████████████████
Epoch 2: Loss = 1.8  ██████████████████████████
Epoch 3: Loss = 1.2  █████████████████
Epoch 4: Loss = 0.8  ████████████
Epoch 5: Loss = 0.5  ███████
         ↓
      Loss 越来越小，模型越来越准
```

---

## 代码示例

```python
import torch
import torch.nn.functional as F

# 交叉熵损失示例
# 模型预测的 logits（未归一化的分数）
logits = torch.tensor([[2.0, 1.0, 0.5]])  # 3 个类别的分数

# 正确答案是第 0 类
target = torch.tensor([0])

# 计算损失
loss = F.cross_entropy(logits, target)
print(f"Loss: {loss.item():.4f}")  # 0.4076

# 如果预测更准确
logits_better = torch.tensor([[5.0, 1.0, 0.5]])
loss_better = F.cross_entropy(logits_better, target)
print(f"Better Loss: {loss_better.item():.4f}")  # 0.0159 (更小)
```

---

## Loss 曲线解读

### 正常训练

```
Loss
  │
  │╲
  │ ╲
  │  ╲___________
  │              
  └──────────────→ Steps
     Loss 平稳下降并收敛
```

### 过拟合

```
Loss
  │     训练 Loss
  │╲    ────────
  │ ╲___________
  │    ╱
  │   ╱  验证 Loss
  │  ╱   - - - - -
  └──────────────→ Steps
     验证 Loss 开始上升 = 过拟合！
```

### 学习率太大

```
Loss
  │    ╱╲  ╱╲
  │   ╱  ╲╱  ╲
  │  ╱        ╲╱
  │ ╱
  └──────────────→ Steps
     Loss 震荡不收敛
```

---

## 与训练参数的关系

| 参数 | 与 Loss 的关系 |
|------|---------------|
| `learning_rate` | 学习率太大 Loss 震荡，太小收敛慢 |
| `num_train_epochs` | 训练轮数多，Loss 更低（但可能过拟合） |
| `per_device_train_batch_size` | Batch 大，Loss 下降更平稳 |
| `logging_steps` | 每隔多少步记录一次 Loss |

---

## 一句话总结

> **Loss** 是模型的"成绩单"，数字越小说明模型学得越好。训练的目标就是让 Loss 最小化。

