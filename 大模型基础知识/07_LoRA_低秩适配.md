# LoRA（Low-Rank Adaptation）低秩适配

## 简单理解

**LoRA** 是一种高效微调方法，不修改原始模型，而是给模型"戴上眼镜"（添加小的适配器），只训练这副"眼镜"。

---

## 类比解释

```
全参数微调：
┌─────────────────────────────────────┐
│ 🧠 把整个大脑重新训练一遍             │
│ 💰 成本高，需要大量资源               │
│ ⏱️ 耗时长                            │
└─────────────────────────────────────┘

LoRA 微调：
┌─────────────────────────────────────┐
│ 🧠 大脑保持不变（冻结）               │
│ 👓 只训练一副"眼镜"（适配器）         │
│ 💰 成本低，资源需求少                 │
│ ⏱️ 速度快                            │
└─────────────────────────────────────┘
```

---

## 原理图解

### 原始 Transformer 层

```
输入 X
   │
   ▼
┌─────────────────┐
│  原始权重 W      │  ← 参数量巨大（如 4096 × 4096 = 16M）
│  (d × k)        │
└─────────────────┘
   │
   ▼
输出 Y = W × X
```

### LoRA 改造后

```
输入 X
   │
   ├──────────────────────────┐
   │                          │
   ▼                          ▼
┌─────────────────┐    ┌─────────────┐
│  原始权重 W      │    │   矩阵 A    │  ← 小矩阵（d × r）
│  (冻结不训练)    │    │   (降维)    │
└─────────────────┘    └─────────────┘
   │                          │
   │                          ▼
   │                   ┌─────────────┐
   │                   │   矩阵 B    │  ← 小矩阵（r × k）
   │                   │   (升维)    │
   │                   └─────────────┘
   │                          │
   ▼                          ▼
   └────────── + ─────────────┘
               │
               ▼
         输出 Y = W×X + B×A×X
```

### 参数量对比

```
原始：W (4096 × 4096) = 16,777,216 参数

LoRA (rank=64)：
- A (4096 × 64) = 262,144 参数
- B (64 × 4096) = 262,144 参数
- 总计：524,288 参数

节省：16,777,216 ÷ 524,288 ≈ 32 倍！
```

---

## LoRA 参数详解

### `lora_rank` (r)

```
rank 越大，表达能力越强，但参数越多

rank = 8:   ████                     （参数少，能力弱）
rank = 32:  ████████████             （适中）
rank = 64:  ████████████████████████ （参数多，能力强）
rank = 128: ████████████████████████████████████████ （接近全参数）

推荐值：32-64（大多数任务够用）
```

### `lora_alpha` (α)

```
缩放因子，控制 LoRA 的影响程度

实际输出 = W×X + (α/r) × B×A×X
                 ↑
              缩放系数

alpha = rank:     缩放系数 = 1（标准）
alpha = 2×rank:   缩放系数 = 2（LoRA 影响更大）
alpha = 0.5×rank: 缩放系数 = 0.5（LoRA 影响更小）

推荐值：rank 的 1-2 倍
```

### `lora_dropout`

```
训练时随机丢弃部分 LoRA 参数，防止过拟合

dropout = 0:    ○○○○○○○○  全部保留
dropout = 0.1:  ○○✗○○○✗○  随机丢弃 10%
dropout = 0.2:  ○✗○○✗○○✗  随机丢弃 20%

推荐值：0.05-0.1
```

---

## LoRA 的优势

| 方面 | 全参数微调 | LoRA 微调 |
|------|-----------|----------|
| 显存占用 | 高（需存储所有梯度） | 低（只存储适配器梯度） |
| 训练速度 | 慢 | 快 |
| 存储空间 | 大（完整模型） | 小（只保存适配器） |
| 多任务切换 | 需要多个完整模型 | 只需切换适配器 |
| 原始能力 | 可能被覆盖 | 完整保留 |

---

## 代码示例

### 使用 Swift 训练 LoRA

```bash
swift sft \
  --model Qwen/Qwen3-8B \
  --train_type lora \
  --lora_rank 64 \
  --lora_alpha 128 \
  --lora_dropout 0.05 \
  --dataset my_dataset \
  --output_dir output_lora
```

### 使用 PEFT 库

```python
from peft import LoraConfig, get_peft_model

# 配置 LoRA
lora_config = LoraConfig(
    r=64,                    # rank
    lora_alpha=128,          # alpha
    lora_dropout=0.05,       # dropout
    target_modules=["q_proj", "v_proj"],  # 应用到哪些层
    bias="none",
    task_type="CAUSAL_LM"
)

# 给模型添加 LoRA
model = get_peft_model(model, lora_config)

# 查看可训练参数
model.print_trainable_parameters()
# 输出：trainable params: 33,554,432 || all params: 8,030,261,248 || trainable%: 0.42%
```

### 加载训练好的 LoRA

```python
from peft import PeftModel

# 加载基础模型
base_model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen3-8B")

# 加载 LoRA 适配器
model = PeftModel.from_pretrained(base_model, "output_lora")

# 合并 LoRA 到基础模型（可选，用于部署）
merged_model = model.merge_and_unload()
```

---

## LoRA 应用场景

### 1. 多任务适配

```
基础模型（Qwen3-8B）
        │
        ├── LoRA-A（客服对话）     → 客服机器人
        │
        ├── LoRA-B（代码生成）     → 编程助手
        │
        ├── LoRA-C（医疗问答）     → 医疗顾问
        │
        └── LoRA-D（法律咨询）     → 法律助手

只需要一个基础模型 + 多个小适配器！
```

### 2. 个性化定制

```
用户 A 的对话风格 → LoRA-用户A
用户 B 的对话风格 → LoRA-用户B
用户 C 的对话风格 → LoRA-用户C

每个用户的 LoRA 只有几十 MB
```

### 3. 快速实验

```
实验不同的数据集：
- 数据集 1 → LoRA-1 (10分钟训练)
- 数据集 2 → LoRA-2 (10分钟训练)
- 数据集 3 → LoRA-3 (10分钟训练)

快速对比效果，选择最佳方案
```

---

## LoRA vs 其他方法

| 方法 | 参数量 | 显存 | 效果 | 说明 |
|------|--------|------|------|------|
| 全参数微调 | 100% | 最高 | 最好 | 更新所有参数 |
| LoRA | ~1% | 低 | 较好 | 低秩适配器 |
| QLoRA | ~1% | 最低 | 一般 | 量化 + LoRA |
| Prefix Tuning | ~0.1% | 低 | 一般 | 只训练前缀 |
| Prompt Tuning | ~0.01% | 最低 | 较差 | 只训练提示 |

---

## 常见问题

### Q: LoRA 效果比全参数差吗？

```
大多数任务：LoRA 效果接近全参数微调（90-95%）
特殊任务：如果任务与预训练差异很大，全参数可能更好
建议：先试 LoRA，不够再考虑全参数
```

### Q: rank 设多少合适？

```
简单任务（风格迁移）：8-32
中等任务（领域适配）：32-64
复杂任务（能力增强）：64-128
```

### Q: 哪些层应该加 LoRA？

```
常见选择：
- q_proj, v_proj（注意力层的 Q 和 V）
- q_proj, k_proj, v_proj, o_proj（全部注意力层）
- 所有线性层（效果最好，但参数更多）
```

---

## 与训练参数的关系

| 参数 | 说明 |
|------|------|
| `--train_type lora` | 启用 LoRA 微调 |
| `--lora_rank` | LoRA 秩（r） |
| `--lora_alpha` | 缩放因子（α） |
| `--lora_dropout` | Dropout 比例 |
| `--lora_target_modules` | 应用 LoRA 的层 |

---

## 一句话总结

> **LoRA** 是给大模型"戴眼镜"的技术——不改变大脑（原始模型），只训练眼镜（适配器），既省资源又效果好。

