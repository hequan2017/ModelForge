# Qwen3 训练脚本参数详细说明

## 一、环境变量

### `CUDA_VISIBLE_DEVICES=0,1,2,3,4`

**作用**：指定 PyTorch 可见的 GPU 设备。

**详细说明**：
- 这是一个环境变量，用于控制程序能够"看到"哪些 GPU
- `0,1,2,3,4` 表示使用编号为 0、1、2、3、4 的五张 GPU
- 如果你的服务器有 8 张 GPU，但只想用前 5 张，就可以这样设置
- GPU 编号从 0 开始，可以通过 `nvidia-smi` 命令查看所有 GPU

**使用场景**：
- 多人共用服务器时，分配不同的 GPU 给不同用户
- 某些 GPU 被占用时，排除这些 GPU
- 测试时只使用部分 GPU

**示例**：
```bash
# 只使用第一张 GPU
export CUDA_VISIBLE_DEVICES=0

# 使用第 2、4、6 张 GPU
export CUDA_VISIBLE_DEVICES=1,3,5

# 不使用任何 GPU（强制使用 CPU）
export CUDA_VISIBLE_DEVICES=""
```

---

## 二、torchrun 分布式训练参数

### `--nproc_per_node=5`

**作用**：指定每个节点（服务器）上启动的进程数。

**详细说明**：
- `nproc` = number of processes（进程数量）
- 通常设置为 GPU 数量，每个进程对应一张 GPU
- 这里设置为 5，对应上面的 5 张 GPU
- 每个进程会独立加载模型副本，并行处理不同的数据批次

**注意事项**：
- 必须与 `CUDA_VISIBLE_DEVICES` 中的 GPU 数量一致
- 进程数越多，并行度越高，但通信开销也越大

---

### `--master_port=29500`

**作用**：指定分布式训练中主进程（rank 0）的通信端口。

**详细说明**：
- 分布式训练需要多个进程之间进行通信（同步梯度、参数等）
- 主进程作为协调者，其他进程通过这个端口与主进程通信
- 默认端口是 29500，如果被占用需要更换

**常见问题**：
- 如果端口被占用，会报错 `Address already in use`
- 解决方法：更换端口号，如 29501、29502 等

**示例**：
```bash
# 查看端口是否被占用
netstat -tlnp | grep 29500

# 如果被占用，换一个端口
--master_port=29501
```

---

### `--no_python`

**作用**：告诉 torchrun 不要用 Python 解释器来运行后面的命令。

**详细说明**：
- 正常情况下，torchrun 会用 `python` 来执行后面的脚本
- 但 `swift` 是一个已经打包好的可执行命令（不是 .py 文件）
- 加上 `--no_python` 后，torchrun 会直接执行 `swift sft` 命令

**对比**：
```bash
# 不加 --no_python（用于 Python 脚本）
torchrun --nproc_per_node=5 train.py

# 加 --no_python（用于可执行命令）
torchrun --nproc_per_node=5 --no_python swift sft
```

---

## 三、Swift SFT 训练参数

### 3.1 模型相关参数

#### `--model Qwen/Qwen3-30B-A3B-Thinking-2507`

**作用**：指定要微调的基座模型。

**详细说明**：
- 可以是 Hugging Face Hub 上的模型 ID（如这里的 `Qwen/Qwen3-30B-A3B-Thinking-2507`）
- 也可以是本地模型路径（如 `/data/models/qwen3-30b`）
- Swift 会自动从 Hugging Face 下载模型（如果本地没有）

**模型命名解析**：
- `Qwen3`: Qwen 第三代模型
- `30B`: 300 亿参数
- `A3B`: 激活参数约 3B（MoE 架构）
- `Thinking`: 思考/推理增强版本
- `2507`: 2025 年 7 月版本

**示例**：
```bash
# 使用 Hugging Face 模型
--model Qwen/Qwen2.5-7B-Instruct

# 使用本地模型
--model /data/models/qwen2.5-7b
```

---

#### `--train_type full`

**作用**：指定训练类型/微调方式。

**详细说明**：

| 训练类型 | 说明 | 显存占用 | 训练效果 |
|---------|------|---------|---------|
| `full` | 全参数微调，更新模型所有参数 | 最高 | 最好 |
| `lora` | LoRA 微调，只训练低秩适配器 | 较低 | 较好 |
| `qlora` | 量化 LoRA，4-bit 量化 + LoRA | 最低 | 一般 |

**全参数微调 (full)**：
- 更新模型的所有权重参数
- 需要更多显存和计算资源
- 训练效果通常最好
- 适合：显存充足、追求最佳效果的场景

**LoRA 微调**：
- 冻结原始模型，只训练额外添加的低秩矩阵
- 显存占用大幅降低（约 1/3 ~ 1/10）
- 训练速度更快
- 适合：显存有限、快速实验的场景

---

#### `--torch_dtype bfloat16`

**作用**：指定模型权重和计算的数据精度。

**详细说明**：

| 精度类型 | 位数 | 显存占用 | 数值范围 | 说明 |
|---------|------|---------|---------|------|
| `float32` | 32 位 | 最高 | 最大 | 全精度，最稳定 |
| `float16` | 16 位 | 较低 | 较小 | 半精度，可能溢出 |
| `bfloat16` | 16 位 | 较低 | 与 float32 相同 | 推荐，兼顾效率和稳定性 |

**bfloat16 的优势**：
- 与 float16 相同的显存占用
- 与 float32 相同的数值范围（不容易溢出）
- 训练更稳定，是目前大模型训练的首选精度
- 需要 Ampere 架构及以上的 GPU（如 A100、RTX 3090、4090）

---

### 3.2 数据集相关参数

#### `--dataset 'liucong/Chinese-DeepSeek-R1-Distill-data-110k#1000'`

**作用**：指定训练数据集。

**详细说明**：
- 格式：`数据集名称#采样数量`
- `liucong/Chinese-DeepSeek-R1-Distill-data-110k`：Hugging Face 上的数据集
- `#1000`：只使用前 1000 条数据（用于测试或小规模训练）

**数据集来源**：
- 这是 DeepSeek-R1 模型的中文蒸馏数据
- 包含约 11 万条高质量中文对话数据
- 适合训练中文推理/思考能力

**多数据集混合**：
```bash
# 使用多个数据集
--dataset 'dataset1#5000' 'dataset2#3000' 'dataset3'

# 使用本地数据集
--dataset /data/my_dataset.jsonl
```

---

#### `--max_length 4096`

**作用**：设置输入序列的最大 token 长度。

**详细说明**：
- Token 是模型处理文本的基本单位（大约 1 个中文字 = 1-2 个 token）
- 超过此长度的文本会被截断
- 长度越大，显存占用越高（显存与长度的平方成正比）

**如何选择**：
- 短文本任务（分类、简单问答）：1024-2048
- 中等长度任务（对话、摘要）：4096
- 长文本任务（长文档理解）：8192-32768

**显存估算**：
- 长度翻倍，注意力机制的显存占用约翻 4 倍
- 4096 长度是性能和显存的较好平衡点

---

#### `--system 'You are a helpful assistant.'`

**作用**：设置系统提示词（System Prompt）。

**详细说明**：
- 系统提示词定义了模型的角色和行为准则
- 会被添加到每条训练数据的开头
- 影响模型的回复风格和能力表现

**常见系统提示词**：
```bash
# 通用助手
--system 'You are a helpful assistant.'

# 中文助手
--system '你是一个有帮助的中文助手。'

# 专业角色
--system '你是一位资深的Python程序员，擅长代码优化和问题排查。'

# 思考链
--system '你是一个善于深度思考的助手。在回答问题前，请先分析问题，逐步推理，然后给出答案。'
```

---

### 3.3 训练超参数

#### `--num_train_epochs 3`

**作用**：设置训练的轮数（Epoch）。

**详细说明**：
- 1 个 Epoch = 遍历整个训练集一次
- 3 个 Epoch 意味着每条数据会被模型看到 3 次
- 轮数越多，模型学习越充分，但也可能过拟合

**如何选择**：
- 数据量大（>10 万条）：1-3 轮
- 数据量中等（1-10 万条）：3-5 轮
- 数据量小（<1 万条）：5-10 轮

**过拟合的表现**：
- 训练损失持续下降，但验证损失开始上升
- 模型在训练集上表现很好，但泛化能力差

---

#### `--per_device_train_batch_size 2`

**作用**：设置每个 GPU 上的训练批次大小。

**详细说明**：
- Batch Size = 每次梯度更新使用的样本数量
- `per_device` 表示这是单个 GPU 的批次大小
- 设置为 2 表示每个 GPU 每次处理 2 条数据

**批次大小的影响**：
- 越大：训练越稳定，但显存占用越高
- 越小：显存占用低，但训练可能不稳定

**显存不足时的处理**：
- 减小 batch_size（如从 2 改为 1）
- 增大 gradient_accumulation_steps 来补偿

---

#### `--per_device_eval_batch_size 1`

**作用**：设置每个 GPU 上的评估批次大小。

**详细说明**：
- 评估时不需要计算梯度，显存占用比训练时少
- 但为了安全起见，通常设置得比训练批次小
- 评估批次大小不影响模型效果，只影响评估速度

---

#### `--gradient_accumulation_steps 8`

**作用**：梯度累积步数，用于模拟更大的批次大小。

**详细说明**：
- 不是每个 batch 都更新参数，而是累积多个 batch 的梯度后再更新
- 效果等同于使用更大的 batch size，但不增加显存

**有效批次大小计算**：
```
有效批次大小 = per_device_train_batch_size × GPU数量 × gradient_accumulation_steps
            = 2 × 5 × 8 = 80
```

**为什么需要梯度累积**：
- 大 batch size 训练更稳定，收敛更快
- 但显存有限，无法直接使用大 batch
- 梯度累积可以在不增加显存的情况下获得大 batch 的效果

**示例**：
```bash
# 显存充足：直接用大 batch
--per_device_train_batch_size 16 --gradient_accumulation_steps 1

# 显存有限：小 batch + 梯度累积
--per_device_train_batch_size 2 --gradient_accumulation_steps 8
# 两者的有效 batch size 相同，但后者显存占用更低
```

---

#### `--learning_rate 1e-5`

**作用**：设置学习率（Learning Rate）。

**详细说明**：
- 学习率决定了每次参数更新的步长
- `1e-5` = 0.00001，这是一个较小的学习率
- 大模型微调通常使用较小的学习率，避免破坏预训练知识

**学习率的影响**：
- 太大：训练不稳定，loss 震荡或发散
- 太小：收敛太慢，训练效率低
- 合适：loss 平稳下降，模型效果好

**推荐学习率**：
| 训练类型 | 推荐学习率 |
|---------|-----------|
| 全参数微调 | 1e-5 ~ 5e-5 |
| LoRA 微调 | 1e-4 ~ 5e-4 |
| 预训练 | 1e-4 ~ 3e-4 |

---

#### `--warmup_ratio 0.1`

**作用**：学习率预热比例。

**详细说明**：
- 预热（Warmup）是指训练初期逐渐增加学习率
- `0.1` 表示前 10% 的训练步数用于预热
- 预热期间，学习率从 0 线性增加到设定值

**为什么需要预热**：
- 训练初期，模型参数随机性较大
- 直接使用大学习率可能导致训练不稳定
- 预热让模型先"热身"，逐渐适应训练过程

**学习率变化曲线**：
```
学习率
  ↑
  │      ╭──────────────╮
  │     ╱                ╲
  │    ╱                  ╲
  │   ╱                    ╲
  │  ╱                      ╲
  └─┴───────────────────────────→ 训练步数
    预热期     正常训练期    衰减期
```

---

#### `--gradient_checkpointing true`

**作用**：启用梯度检查点，用时间换显存。

**详细说明**：
- 正常训练时，前向传播的中间结果需要保存，用于反向传播计算梯度
- 这些中间结果占用大量显存
- 梯度检查点：不保存中间结果，需要时重新计算

**优缺点**：
- 优点：显存占用减少约 30%-50%
- 缺点：训练速度降低约 20%-30%（需要重新计算）

**适用场景**：
- 显存紧张时必开
- 显存充足且追求训练速度时可关闭

---

### 3.4 评估与保存参数

#### `--eval_strategy steps`

**作用**：指定评估策略。

**详细说明**：
| 策略 | 说明 |
|------|------|
| `no` | 不进行评估 |
| `steps` | 按步数评估 |
| `epoch` | 每个 epoch 结束时评估 |

- 设置为 `steps` 后，需要配合 `--eval_steps` 使用
- 评估可以帮助监控模型是否过拟合

---

#### `--eval_steps 50`

**作用**：每隔多少步进行一次评估。

**详细说明**：
- 每训练 50 步，在验证集上评估一次模型性能
- 评估会计算验证集的 loss 等指标
- 可以通过评估结果判断模型是否过拟合

**如何选择**：
- 数据量小：设小一些（如 20-50）
- 数据量大：设大一些（如 100-500）
- 太频繁会影响训练速度

---

#### `--save_steps 50`

**作用**：每隔多少步保存一次模型检查点。

**详细说明**：
- 每 50 步保存一次模型权重
- 保存的检查点可用于：
  - 训练中断后恢复
  - 选择最佳模型
  - 回溯到之前的版本

**检查点内容**：
- 模型权重
- 优化器状态
- 训练进度信息
- 配置文件

---

#### `--save_total_limit 3`

**作用**：最多保留多少个检查点。

**详细说明**：
- 只保留最近的 3 个检查点，更早的会被自动删除
- 防止检查点占用过多磁盘空间
- 30B 模型每个检查点约 60GB，3 个就是 180GB

**如何选择**：
- 磁盘空间充足：可以设大一些（5-10）
- 磁盘空间紧张：设小一些（2-3）
- 设为 -1 或不设置：保留所有检查点

---

#### `--logging_steps 5`

**作用**：每隔多少步记录一次训练日志。

**详细说明**：
- 每 5 步输出一次训练信息（loss、学习率、速度等）
- 日志可以帮助监控训练进度
- 设置太小会产生大量日志，设置太大则难以及时发现问题

**日志示例**：
```
Step 5: loss=2.345, lr=1e-6, speed=1.2 samples/s
Step 10: loss=2.123, lr=2e-6, speed=1.3 samples/s
Step 15: loss=1.987, lr=3e-6, speed=1.2 samples/s
```

---

#### `--output_dir output_qwen3_30b_full`

**作用**：指定模型输出目录。

**详细说明**：
- 所有训练产物都会保存到这个目录
- 包括：检查点、最终模型、训练日志、配置文件等

**目录结构示例**：
```
output_qwen3_30b_full/
├── checkpoint-50/          # 第 50 步的检查点
├── checkpoint-100/         # 第 100 步的检查点
├── checkpoint-150/         # 第 150 步的检查点
├── runs/                   # TensorBoard 日志
├── trainer_state.json      # 训练状态
├── training_args.bin       # 训练参数
└── all_results.json        # 训练结果
```

---

### 3.5 数据加载参数

#### `--dataloader_num_workers 4`

**作用**：数据加载的并行工作进程数。

**详细说明**：
- 数据加载和模型训练是可以并行的
- 多个 worker 可以在 GPU 训练时预先加载下一批数据
- 避免 GPU 等待数据，提高训练效率

**如何选择**：
- 一般设置为 CPU 核心数的 1/4 到 1/2
- 太多会占用过多 CPU 和内存
- 太少可能导致数据加载成为瓶颈

**常见问题**：
- 如果遇到内存不足，可以减小这个值
- Windows 系统有时设为 0 更稳定

---

### 3.6 模型元信息参数

#### `--model_author swift`

**作用**：设置模型作者信息。

**详细说明**：
- 这个信息会写入模型的配置文件
- 方便追踪模型来源
- 在模型分享时标识作者

---

#### `--model_name swift-robot`

**作用**：设置模型名称。

**详细说明**：
- 给微调后的模型起一个名字
- 写入模型配置文件
- 便于区分不同版本的模型

---

### 3.7 分布式训练优化参数

#### `--deepspeed zero2`

**作用**：启用 DeepSpeed ZeRO-2 优化策略。

**详细说明**：

DeepSpeed 是微软开发的深度学习优化库，ZeRO（Zero Redundancy Optimizer）是其核心技术。

**ZeRO 各级别对比**：

| 级别 | 分片内容 | 显存节省 | 通信开销 | 适用场景 |
|------|---------|---------|---------|---------|
| ZeRO-1 | 优化器状态 | 约 4x | 低 | 中等规模模型 |
| ZeRO-2 | 优化器状态 + 梯度 | 约 8x | 中 | 大规模模型 |
| ZeRO-3 | 优化器状态 + 梯度 + 参数 | 约 16x | 高 | 超大规模模型 |

**ZeRO-2 的工作原理**：
1. 将优化器状态分片到各个 GPU
2. 将梯度分片到各个 GPU
3. 每个 GPU 只存储部分状态，需要时通过通信获取

**为什么选择 ZeRO-2**：
- ZeRO-1 节省不够多
- ZeRO-3 通信开销太大，训练速度慢
- ZeRO-2 是性能和显存的较好平衡

**使用建议**：
```bash
# 模型较小（<10B），显存充足
不使用 DeepSpeed 或使用 ZeRO-1

# 模型中等（10B-70B）
--deepspeed zero2

# 模型超大（>70B）或显存非常紧张
--deepspeed zero3
```

---

## 四、完整训练流程图解

```
┌─────────────────────────────────────────────────────────────────┐
│                        训练开始                                  │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  1. 环境初始化                                                   │
│     - 设置 CUDA_VISIBLE_DEVICES，分配 GPU                        │
│     - torchrun 启动 5 个进程，每个进程绑定一个 GPU                 │
│     - 初始化 DeepSpeed ZeRO-2                                    │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  2. 加载模型和数据                                               │
│     - 从 HuggingFace 下载 Qwen3-30B 模型                         │
│     - 以 bfloat16 精度加载模型权重                                │
│     - 加载数据集的前 1000 条数据                                  │
│     - 启用梯度检查点节省显存                                      │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  3. 训练循环（3 个 Epoch）                                       │
│                                                                 │
│     ┌─────────────────────────────────────────────────────┐     │
│     │  每一步（Step）:                                     │     │
│     │  - 4 个 worker 并行加载数据                          │     │
│     │  - 每个 GPU 处理 2 条数据                            │     │
│     │  - 累积 8 步梯度后更新参数                           │     │
│     │  - 有效 batch size = 2 × 5 × 8 = 80                 │     │
│     └─────────────────────────────────────────────────────┘     │
│                              │                                  │
│     每 5 步：记录日志（loss、学习率等）                           │
│     每 50 步：评估模型 + 保存检查点                               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  4. 训练完成                                                     │
│     - 保存最终模型到 output_qwen3_30b_full/                      │
│     - 只保留最近 3 个检查点                                      │
│     - 输出训练统计信息                                           │
└─────────────────────────────────────────────────────────────────┘
```

---

## 五、常见问题与调优建议

### 显存不足（OOM）怎么办？

1. **减小批次大小**：`--per_device_train_batch_size 1`
2. **增大梯度累积**：`--gradient_accumulation_steps 16`
3. **减小序列长度**：`--max_length 2048`
4. **启用梯度检查点**：`--gradient_checkpointing true`
5. **使用更激进的 ZeRO**：`--deepspeed zero3`
6. **改用 LoRA 微调**：`--train_type lora`

### 训练速度太慢怎么办？

1. **增大批次大小**（如果显存允许）
2. **增加数据加载 worker**：`--dataloader_num_workers 8`
3. **关闭梯度检查点**（如果显存充足）
4. **使用 ZeRO-2 而非 ZeRO-3**

### 训练不稳定（loss 震荡）怎么办？

1. **减小学习率**：`--learning_rate 5e-6`
2. **增大预热比例**：`--warmup_ratio 0.2`
3. **增大批次大小**（有效 batch size）

### 模型过拟合怎么办？

1. **减少训练轮数**：`--num_train_epochs 1`
2. **增加数据量**
3. **使用更小的学习率**
4. **添加正则化（如 dropout）**
